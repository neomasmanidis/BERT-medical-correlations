{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52f887e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "from transformers import AutoTokenizer,AutoModel, BertConfig\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25e5b1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a5b2f612c0435cb8a55e3e278d9c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9df5aaeaa1542b1bbe86c928691d3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/159M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bioformers/bioformer-16L were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07f5e0a26c34e5e9a86c2db7c9adf29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb6a79451114ef2a010b79d8f1ef8e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/242k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_name='microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext'\n",
    "# model_name=\"bert-base-uncased\"\n",
    "# model_name=\"dmis-lab/biobert-base-cased-v1.2\"\n",
    "model_name=\"bioformers/bioformer-16L\"\n",
    "\n",
    "config = BertConfig.from_pretrained(model_name, output_hidden_states=True)\n",
    "model = AutoModel.from_pretrained(model_name, config=config)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_name)\n",
    "# model=AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4e21723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kegg_graph(data_df, include_reactions = True):\n",
    "    \n",
    "    G = nx.MultiDiGraph()  # At first create multigraph, later it can be converted\n",
    "    \n",
    "    unique_entries = []  # List of unique entries. Each gene, ompound, etc needs to be stored as 1 node\n",
    "    \n",
    "    # Iterate data to create all nodes\n",
    "    for index, entry in tqdm(data_df.iterrows(), total=data_df.shape[0]):\n",
    "        \n",
    "        if not include_reactions and entry['link type']=='reaction':\n",
    "            continue            \n",
    "        \n",
    "        # -- Handle node for Head --\n",
    "        n1 = entry['head id']\n",
    "        if n1 not in unique_entries:  # If there is no node for this id yet\n",
    "            \n",
    "            unique_entries.append(n1)\n",
    "            \n",
    "            #Add node n1\n",
    "            G.add_node(n1)\n",
    "            # Assign node type\n",
    "            if n1[0:3] == 'hsa':\n",
    "                t = 'gene'\n",
    "            elif n1[0:3] == 'cpd':\n",
    "                t = 'compound'\n",
    "            else:\n",
    "                temp = n1.split(\":\")\n",
    "                t = temp[0]\n",
    "            # Assign rest of node attributes\n",
    "            if entry['head full name'] == '':\n",
    "                full_name = n1\n",
    "            else:\n",
    "                full_name = entry['head full name']\n",
    "            pathway = str(entry['pathway'])\n",
    "            attr = {n1: {'type':t, 'full name': full_name, 'pathways': [pathway]}}\n",
    "            nx.set_node_attributes(G, attr)\n",
    "            \n",
    "        else:  # If there is a node for this id already\n",
    "            # Add the pathway info (if different pathway)\n",
    "            temp = G.nodes[n1]['pathways']\n",
    "            if entry['pathway'] not in temp:\n",
    "                temp.append(entry['pathway'])\n",
    "                G.nodes[n1]['pathways'] = temp\n",
    "\n",
    "        # -- Handle node for Tail --\n",
    "        n2 = entry['tail id']\n",
    "        if n2 not in unique_entries:  # If there is no node for this id yet\n",
    "            \n",
    "            unique_entries.append(n2)\n",
    "            \n",
    "            #Add node n2\n",
    "            G.add_node(n2)\n",
    "            # Assign node type\n",
    "            if n2[0:3] == 'hsa':\n",
    "                t = 'gene'\n",
    "            elif n2[0:3] == 'cpd':\n",
    "                t = 'compound'\n",
    "            else:\n",
    "                temp = n2.split(\":\")\n",
    "                t = temp[0]\n",
    "            # Assign rest of node attributes\n",
    "            if entry['tail full name'] == '':\n",
    "                full_name = n2\n",
    "            else:\n",
    "                full_name = entry['tail full name']\n",
    "            pathway = str(entry['pathway'])\n",
    "            attr = {n2: {'type':t, 'full name': full_name, 'pathways': [pathway]}}\n",
    "            nx.set_node_attributes(G, attr)\n",
    "            \n",
    "        else:  # If there is a node for this id already\n",
    "            # Add the pathway info (if different pathway)\n",
    "            temp = G.nodes[n2]['pathways']\n",
    "            if entry['pathway'] not in temp:\n",
    "                temp.append(entry['pathway'])\n",
    "                G.nodes[n2]['pathways'] = temp\n",
    "        \n",
    "        \n",
    "     # Iterate data to find all relations           \n",
    "    for index, row in tqdm(data_df.iterrows(), total=data_df.shape[0]):\n",
    "        \n",
    "        if not include_reactions and row['link type']=='reaction':\n",
    "            continue \n",
    "        \n",
    "        head = str(row['head id'])\n",
    "        tail = str(row['tail id'])\n",
    "        pathway = str(row['pathway'])\n",
    "        link_type = str(row['link type'])\n",
    "        rel_name = str(row['relation name'])\n",
    "        if head in G.nodes and tail in G.nodes:\n",
    "            G.add_edge(head, tail,pathway = pathway, link_type= link_type, relation_name= rel_name)\n",
    "        else:\n",
    "            print('node not found @row '+str(index))\n",
    "        \n",
    "    return G\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28cc6de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 17448/17448 [00:02<00:00, 6670.71it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 17448/17448 [00:01<00:00, 12682.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 5187 nodes and 11804 edges\n"
     ]
    }
   ],
   "source": [
    "# === load data ===\n",
    "df_relations = pd.read_csv('../KEGG Pathways Dataset Collection/All_relations-Curated-full_names.csv')\n",
    "G_directed = create_kegg_graph(df_relations)\n",
    "G_undirected = nx.Graph(G_directed)\n",
    "print(G_undirected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27f456fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of all the node full names\n",
    "total_ls = []\n",
    "\n",
    "for node in  G_undirected.nodes:\n",
    "    total_ls.append(str(G_undirected.nodes[node]['full name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f4e6e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5187/5187 [05:36<00:00, 15.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# Make a dictionary to map each full name to an embedding representation\n",
    "d = {}\n",
    "for node in tqdm(total_ls):\n",
    "    inputs=tokenizer(node, return_tensors='pt')\n",
    "    outputs=model(**inputs)\n",
    "    last_hidden_states=outputs.last_hidden_state\n",
    "    cls_token=last_hidden_states[0][0].detach().numpy()\n",
    "    d[node] = cls_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "294710be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or select the last 4 hidden states aoutputs\n",
    "# d = {}\n",
    "# for node in tqdm(total_ls):\n",
    "#     inputs=tokenizer(node, return_tensors='pt')\n",
    "#     outputs=model(**inputs)\n",
    "\n",
    "#     cls1 = outputs[2][0][0][0].detach().numpy()\n",
    "#     cls2 = outputs[2][1][0][0].detach().numpy()\n",
    "#     cls3 = outputs[2][2][0][0].detach().numpy()\n",
    "#     cls4 = outputs[2][3][0][0].detach().numpy()\n",
    "#     cls_list = np.concatenate([cls1, cls2, cls3, cls4])\n",
    "#     d[node] = cls_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4b73a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as pickle file\n",
    "pickle_out=open('node_embeddings_dict_BioFormer.pkl','wb')\n",
    "pickle.dump(d,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5b25bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save as csv\n",
    "# df = pd.DataFrame(d)\n",
    "# df.to_csv('node_embeddings_dict.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
